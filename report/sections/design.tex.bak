%! TEX root = ../report.tex

\chapter{Design}\label{chp:design}
    \section{Layered Architecture}
        \begin{figure}[H]
            \fontsize{7pt}{7pt}
            \centering
            \begin{tikzpicture}[node distance=1.9em and 2.0em]
                \node [box] (rs) {Raw Socket};
                \node [box, above = of rs] (e) {Ethernet};
                \node [box, above = of e] (ipv4) {IPv4};
                \node [box, above right = of ipv4, xshift=-3em] (tcp) {TCP};
                \node [box, above left = of ipv4,xshift=3em] (icmp) {ICMP};
                \node [box, left = of e] (arp) {ARP};
                \node [box, above = of arp] (r) {Routing};
                \node [box, right = of rs] (tap) {TAP device};
                \node [box, above = of tap] (tun) {TUN device};

                \node [left  = of rs, xshift=-5em] (1) {\parbox[l]{6.5em}{\raggedleft\textcolor{gray}{\textit{Physical (0)}}}};
                \node [above = of 1]               (2) {\parbox[l]{6.5em}{\raggedleft\textcolor{gray}{\textit{Link (1)}}}};
                \node [above = of 2]               (3) {\parbox[l]{6.5em}{\raggedleft\textcolor{gray}{\textit{Internet (2)}}}};
                \node [above = of 3]               (4) {\parbox[l]{6.5em}{\raggedleft\textcolor{gray}{\textit{Transport (3)}}}};

                \draw[-] (rs) -- (e);
                \draw[-] (e.south east) -- (tap.north west);
                \draw[-] (ipv4.south east) -- (tun.north west);
                \draw[-{Stealth[open,scale=1.6]}] (e) -- (ipv4);
                \draw[-{Stealth[open,scale=1.6]}] (ipv4) -- (r);
                \draw[-{Stealth[open,scale=1.6]}] (r.south east) -- (e.north west);
                \draw[-] (arp) -- (r);
                \draw[-] (arp) -- (e);
                \draw[-] (ipv4) -- (tcp.south);
                \draw[-] (ipv4) -- (icmp.south);
            \end{tikzpicture}
            \caption{Protocol layers}\label{fig:layer-arch}
        \end{figure}

        Network protocols are, by design, layered as demonstrated in Figure~\ref{fig:layer-arch}. This design feature can be used as a building block to structure, both semantically and in code, how the program layers will slot together. At the bottom of modern networks is the \emph{link layer}, in almost every case \emph{ethernet}. At this level, whole packets `datagrams' are exchanged between the outside world and the network stack through one or more \emph{interface}s.
        
        Within the ethernet packets can reside many different protocols; the particular one of importance for most internet applications is the \emph{internet protocol}, specifically version 4. It should be noted that the newer and much improved IPv6 should also be accessible here, as a drop-in replacement, or to be run alongside IPv4 at the same time.

        Resolution of 48-bit ethernet hardware addresses, required for routing IPv4 packets to devices on the local network before they can be sent, is performed by the \emph{address resolution protocol} (ARP). This protocol also leverages the lower ethernet packets as transport.

        The ambiguity of payload type within the ethernet packets is resolved with a type field in the header of the ethernet packet with fixed values defined by IEEE~\cite{ieee-ethertype}. Given this information, a choice can be made for each incoming packet to which upper layer protocol the data should be forwarded to. This pluggable design makes implementation simple as well as future compatibility with newer protocols.

        Much like the nested and layered nature of ethernet and inner protocols, the internet protocol is much the same. Two of the vast collection of protocols that run within IP that this software is focussing on are \emph{transmission control protocol} (TCP) and \emph{internet control message protocol} (ICMP)\@. Whilst both having a completely different structure and design, both IPv4 and IPv6 share one common trait: they are interchangeable in the sense that the data they carry is identical and the link layers that carry them are the same. Provided two or more communicating hosts in a connection support one common IP version a link can be established, providing the same internet communication layer guarantees for upper protocols, regardless of IP version used.

        The method used for sending and receiving packets is unimportant but the interface for doing so must be standardised to allow for interchangeable interfaces at runtime (see~Section~\ref{sec:intf}). Depending on the operating system or use case requirements, it may be preferable to use different interface implementations for the situation.

            \subsection{Interface Types}
            Available types of interface will vary based on the operating system and software and hardware support. Based on the features available in Linux at current, a list of potential interface types has been collated:

            The first standard and portable for interfacing with the network hardware is through \emph{raw sockets} using the standard \gls{BSD} socket \gls{API}. Ethernet frames are exchanged with standard \texttt{sendto} and \texttt{recvfrom} calls. This method has the advantage that it is highly portable and should work on most, if not all, Unix systems. One downside is that transmission of packets between the kernel and userspace requires a context switch which has a relatively high temporaly overhead. In large volumes, constant context switches can be detrimental to throughput performance.

            Similar in operation to \emph{raw sockets}, TAP and TUN devices are another portable method for interfacing directly with the lower layers of the kernel networking. TUN/TAP interfaces provide a \emph{file descriptor} which directly correspond to a paired interface in the kernel networking stack. These twin interfaces can be routed or bridged much like real network interfaces, joining software networking with physical networks. TUN devices carry IP traffic and rely on the routing in the kernel. TAP devices communicate ethernet frames and are much closer to the wire than TUN. Also like raw sockets, there is an overhead of the context switch when reading and writing packets into the file descriptor. In most cases TUN/TAP provide the most flexible configuration at runtime, at the cost of some performance.

            Many operating systems provide low-overhead interfaces for transferring large volumes of packets between kernel and userspace. Often zero-copy implementations rely upon mapped memory regions shared between the user application and kernel. Linux provides an interface called \emph{tpacket}~\cite{tpacket} which leverages a lockless ring buffer for passing packets into userspace. FreeBSD similarly has \emph{netmap}~\cite{netmap} which operates in a very similar way. These interfaces have the great advantage that passing packets into the kernel has a minimal overhead as significantly fewer context switches are required to send and receieve packets. Unfortunately specific operating system support is usually required and support varies between operating systems and even different versions of the same kernel.

    \section{TCP buffer management}
        As specified in RFC793~\cite{rfc793}, there is no requirement to retain out-of-order received segments, nor is it required to reconstruct outgoing retransmission segments, but in both cases retaining this extra data can be useful. Typically this optimisation can yield minor improvements in performance at the cost of greater memory usage or additional re-computation.

        Historically, copying data between buffers has been slow so the number of buffers used should be kept to a minimum. Modern memory copy implementations are highly optimised and the overhead is minimal in comparison to naively copying bytes but should still be considered.

        \subsection{Transmission Buffers}
            Caching of outgoing segments before \texttt{ACK}s arrive can negate the requirement for an additional send buffer to hold the unacknowledged data however does also require retaining the potentially unwanted header information attached to the stored packets too. To reduce retransmission overhead, it is common to simply retransmit the original segments instead of reconstructing them from more up-to-date information. Implementations in popular operating systems like Linux and Windows use a hybrid approach where one or more of the original segments is retransmitted initially followed by newly crafted packets upon receipt of an ACK for the initial retransmission(s). \\ % chktex 36
            There are both benefits and drawbacks to this approach, one being that retransmitted segments do not have to be recomputed, reducing computational overhead. Unmodified segments will likely not contain the latest control information such as window size or \texttt{ACK} value; in this case these packets will be almost indistinguishable to a delayed segment to the peer TCP\@.

            In some cases, partially full packets are retransmitted which can be considered unfulfilled potential as the ratio of control information to payload is lower than optimal when there is extra data in the retransmission queue. Reconstructing or amending smaller segments, incorporating more data to saturate the packet, can improve throughput and reduce latency. One of the major performance-limiting factors of TCP connections, especially those over high-latency links, is waiting for replies or timeouts. When the quantity of packets sent (and as a result, waited on) can be reduced, the delay in completing transfer can be ultimately reduced.

            The strategy chosen for this implementation was using a copy-through send buffer requiring every segment to be recomputed before retransmission. It has the immediate advantage of being much simpler to implement as no management of stored frames needs to occur as well as the other advantages of every sent segment being as up-to-date as possible and the lower storage overhead.

        \subsection{Receive Buffers}
            It is completely valid to immediately discard an incoming out-of-order segment as is the default behaviour of many primitive embedded TCP stacks. In doing so the receiving TCP is committing to the requirement that the sender \textit{must} retransmit the dropped segment as it cannot be acknowledged.

            Most competent TCP implementations queue out-of-order segments for later processing as their sequence number becomes the next awaited unacknowledged value. There are many considerations that go along with this approach such as much of the control information attached to the queued packets (e.g.\ the send window) should be considered outdated and therefore invalid. \\
            As well as data segments, control-only packets such as FIN segments should also be retained so that they do not have to be retransmitted- an out-of-order FIN should be treated the same as an out-of-order data segment.

            Much like the send buffer, the reasoning for the choice of received packet buffering was for ease of implementation, without wastefully dropping segments. All incoming segments are pushed, in sequence, into a receive queue, ready to be retrieved by a successive \texttt{recv} call by the user process. \\
            Whilst this does not allow for queuing of common out-of-order FIN control segments, it does accommodate for regular data segment reordering significantly reducing retransmission occurrences, especially in lossy environments.

    \section{Language choice}
        The nature of networking applications defines them as intricate systems programs that demand equally low-level programming languages to maintain good efficiency to provide sufficient throughput and performance.

        Choosing a programming language for implementing software is often a tradeoff between development speed and runtime performance. Languages that provide simplicity and abstraction tend to perform worse, as a general rule of thumb. Candidate languages chosen for this project along with justifications for suitability are as follows:

        \begin{itemize}
            \item \textbf{C}\enspace{} As the universal standard for systems programming since the birth.of modern operating systems, there are many reasons to choose C. Raw memory manipulation access and the powerful preprocessor as well as the simple syntax and feature-set are compelling reasons for choosing it. The lack of abstraction and high-lever programming paradigms such as object-orientation can increase development time and code verbosity.
            \item \textbf{C\texttt{++}}\enspace{} Extending on the features provided by C, adding many the missing abstractions that simplify programming somewhat. The large feature-set and often feel overwhelming and cumbersome in comparison to the simplicity of its predecessor. Overall strikes a good balance between ease-of-use and performance.
            \item \textbf{Rust}\enspace{} The latest in modern systems programming languages built with the experience of the past 50 years. Boasting zero-cost abstractions and proven memory safety with comparable performance to C and C\texttt{++}. In most cases a decent choice but often with a learning curve.
            \item \textbf{Go}\enspace{} Providing high-level simplicity and abstraction with minimal overhead allowing for an easy programming experience. Built-in concurrency primitives simplify locking and multithreaded communication however the only language sporting garbage collection doesn't lend itself to memory efficiency as much.
        \end{itemize}

        

    % standard format for returning errors
    \section{Error Handling}
        As with most things in C, error handling must be implemented by the programmer. There are many ``standard'' methods of handling errors and they vary wildly between projects. The standard used by POSIX defined \texttt{libc} functions requires the use of a thread-local/global variable to track error values, known as \texttt{errno} and is roughly defined as follows:
        \begin{center}
            \begin{minipage}{0.88\columnwidth}
                \begin{itemize}[noitemsep]
                    \item{\texttt{return\ \ -1} on error, setting \texttt{errno}}
                        \begin{itemize}
                            \item[]{\small e.g.\ \texttt{errno = EINVAL;\ return -1}}
                        \end{itemize}
                    \item{\texttt{return = 0} on success}
                    \item{\texttt{return > 0} with value}
                \end{itemize}
            \end{minipage}
        \end{center}
        \vspace{\parskip}

        For this project I opted to use a similar but cleaner approach:
        \begin{center}
            \begin{minipage}{0.88\columnwidth}
                \begin{itemize}[noitemsep]
                    \item{\texttt{return < 0} on error, negative value}
                        \begin{itemize}
                            \item[]{\small e.g.\ \texttt{return -EINVAL}}
                        \end{itemize}
                    \item{\texttt{return = 0} on success}
                    \item{\texttt{return > 0} with value}
                        \begin{itemize}
                            \item[]{\small e.g.\ \texttt{return 20 \textcolor{gray}{\# num of bytes read}}}
                        \end{itemize}
                \end{itemize}
            \end{minipage}
        \end{center}
        \vspace{\parskip}

        Having a well-defined standard for how errors should be handled removed any ambiguity in the code about how errors should be handled. Even though the semantics differs from that used by standard library functions, it integrated very easily with the use of a standard pattern, mapping from one to the other.

        This simpler design has two immediate advantages over the \texttt{libc} standard approach:
        \begin{itemize}[noitemsep]
            \item{There is no requirement for a global error storage; errors are just returned from the function call with no (extra) side-effects.}
            \item{Memory utilisation of return values is better as there is less wasted space of values less than 1. POSIX defines \texttt{ssize\_t} `to represent sizes of blocks that can be read or written in a single operation.' It must be a signed type to be able to accommodate -1, 0 and positive block sizes. On most (probably all) systems, it is defined as a signed long integer meaning any values representable less than -1 are unused.}
        \end{itemize}

